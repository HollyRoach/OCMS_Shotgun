"""
=============================
pipeline_classifyreads.py
=============================
This pipeline is a wrapper for pipeline_kraken2.py and pipeline_humann3.py. This wrapper pipeline is useful if you prefer to run one pipeline that performs all steps needed to classify reads (as opposed to executing pipelines individualls).

Overview
========
Classify reads with either kraken2/bracken or humann3. Classifying with kraken2/bracken will run pipeline_kraken2.py to classify reads with kmer-based taxonomic mapping (kraken2) and estimate abundances with bracken. Classifying with humann3 will run pipeline_humann3.py to classify readsand annotate genes and pathways with Humann3.

Configuration
=============
The pipeline requires a configured :file:`pipeline.yml` file.

Default configuration file can be generated by executing"
    python <srcdir>/pipeline_classifyreads.py config

Input files
=============
fastq files that are in the format .fastq.1.gz and .fastq.2.gz.

Dependences
==============
For pipeline_kraken2.py
kraken2
bracken

module load Kraken2/2.0.9-beta-gompi-2020a-Perl-5.30.2
module load Bracken/2.6.0-GCCcore-9.3.0

For pipeline_humann3.py
Humann3
Bowtie3
DIAMOND
Pandoc

module load Bowtie2/2.4.1-GCC-9.3.0
module load DIAMOND/0.9.36-GCC-9.3.0
module load Pandoc/2.13

Pipeline output
===============

Code
====
"""

import sys
import shutil
import os
import re
import glob
from pathlib import Path
from ruffus import *
from cgatcore import pipeline as P
from cgatcore import experiment as E

def main(argv=None):
    # read command line argument
    parser = cmdline.get_argparse(description="Wrapper pipeline to classify reads with either pipeline_kraken2 or pipline_humann3")
    parser.add_argument('cmd',  nargs="*", help="pipeline task task to run")
    
    parser.add_argument("-cf", "--cgatflags", dest="cgatflags", help="Job parameters to be passed to cgat. e.g. '-p2 -v5'")
    
    args = parser.parse_args()

    '''create default configuration files in `path`.
    '''
    if args.cmd[0] == 'config':
        pipeline_path = os.path.splitext(__file__)[0]
        general_path = os.path.join(os.path.dirname(pipeline_path), "configuration")
        paths = [pipeline_path, general_path]

        config_files = ['pipeline_classifyreads.yml']

        for dest in config_files:
            if os.path.exists(dest):
                E.warn("file `%s` already exists - skipped" % dest)
                continue

            for path in paths:
                src = os.path.join(path, dest)
                if os.path.exists(src):
                    shutil.copyfile(src, dest)
                    E.info("created new configuration file `%s` " % dest)
                    break
            else:
                raise ValueError(
                    "default config file `%s` not found in %s" %
                    (config_files, paths))

    else:
        # run pipeline from commandline
        statement = " ".join(args.cmd)
        statement = "ocms_shotgun " + statement

        # pass flags to run statement
        if args.cgatflags is not None:
            statement = statement + " " + args.cgatflags
        
        # run ocms_shotgun
        os.system(statement)

        def main(argv=None):
            main(argv)
    if __name__ == "__main__":
        sys.exit(main(sys.argv))
